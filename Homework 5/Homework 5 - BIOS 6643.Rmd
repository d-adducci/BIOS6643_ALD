---
title: "Homework 5 - BIOS 6643"
author: "Dominic Adducci"
date: "2023-09-28"
output: pdf_document
---

```{r, echo = F, message = F, include = F}

library(tidyverse)
library(lme4)
library(lmerTest)
library(broom.mixed)
library(kableExtra)

```

We received data on the blood levels of measles vaccine titers collected randomly over an average of 12 years on 39 subjects. The science of interest was to estimate whether many decades after measles vaccination there was still a significant decay of the vaccine titers. This information will be used to determine whether boosters are needed. 

# Question 1
\
Conduct a preliminary data investigation on the titer data. Analysis will be conducted on the log scale. Please make graphs on this scale. Include in your homework submission 2-3 graphs and a summary table that you believe describes the data. Interpret both the graphs and the summary data in a paragraph. 

```{r, echo = F}

### START QUESTION 1 CODE ###

# Entering data in R. 
measles_raw <- read_csv("C:/Users/domin/Documents/Biostatistics Masters Program/Fall 2023/BIOS 6643 - ADL/BIOS6643_ALD/Homework 5/measlestiter.csv")

# Converting titer measurements to log scale.
measles_raw$Avg_Titer_Log <- log(measles_raw$Avg..Titer)

# Formatting names of columns. 
colnames(measles_raw) <- c("Sample","ID","Age_At_Draw","Avg_Titer","Avg_Titer_Log")

# Removing observation with missing titer data. 
measles_data <- na.omit(measles_raw)

```

```{r, echo = F, warning = F}

# Making a spaghetti plot showing change in average titers as subjects age. 
measles_spaghetti <- ggplot(measles_data,aes(x = Age_At_Draw,
                                             y = Avg_Titer_Log,
                                             group = ID)) +
  geom_point() +
  geom_line() +
  labs(title = "Log(Avg. Titer) vs. Age by ID",
       x = "Age", y = "Log(Avg. Titer)") +
  theme_bw()

# Outputting the plot.
measles_spaghetti

```

```{r, echo = F}



```


# Question 2: Random Intercept Model

#### Part A
Write out the random intercept model for these data in subject level notation including indices for matrices. 

$$Y_i = X_i\beta + Z_ib_i + E_i$$
Where each matrix has the following dimensions:

* $Y_i: (n_i \times 1)$; $n_i$ refers to the number of time points (age). Outcome is the log of average titer. 
* $X_i: (n_i \times p)$; $n_i$ refers to the number of time points(age) and p is the number of covariates plus the intercept. The only covariates are the number of time points (age).
* $\beta: (p \times 1)$; $p$ refers to the number of covariates (measurements at a certain age plus the intercept). 
* $Z_i: (n_i \times q)$; $n_i$ refers to the number of time points (age). $q$ refers to the number of covariates for the random effects. In this case there is only a random intercept, so $q=1$. 
* $b_i: (q \times 1)$; $q$ refers to the number of covariates for the random effects. In this case there is only one random intercept, so $q=1$. 
* $E_i: (n_i \times 1)$; $n_i$ refers to the number of time points (age). Each individual outcome has its own error term. 

#### Part B
What is the format for $G_i$ and $R_i$ that will be assumed in the lmer R function when you fit the random intercept model? Please write the format for these two matrices and interpret. 

The variability of the random effect will be a matrix with $(q_i \times q_i)$ dimensions. Because there is only one random effect, the random intercept, this will be a matrix with a single element for all subjects.  
$$G_i = [\tau_0^2] = [\sigma_0^2]$$
It is usually not possible to estimate both $G$ and an unstructured $R_i$, meaning that $R_i=\sigma_e^2I_n$ (an independence matrix). The dimensions of $R_i$ are $(n_i \times n_i)$, which in this case means a square matrix where $n_i$ is the number of time points (measurements at different ages) for each subject. Because different subjects have different time points the dimensions of the $R_i$ matrix will change between subjects. 

#### Part C
Will $G_i$ and $R_i$ be the same dimension for each individual? Explain. 

For $G_i$ the dimensions will be the same between all subjects because each subject only has a random intercept. The dimension of $G_i$ are $(q_i \times q_i)$, where $q_i$ refers to the number of random effects. Because this model only includes a random intercept $q_i$ will be equal to 1, and the matrix will simply contain a single element of $\tau_0^2=\sigma_0^2$. 

$R_i$ will not be the same between subjects because there are different numbers of time points for each subject. The dimensions of $R_i$ are $(n_i \times n_i)$, where $n_i$ refers to the number of individual time points (age at sample collection). 

#### Part D
Fit a random intercept model for these data using the lmer R function with REML and ML estimation approaches. Provide you code and output. 

```{r}

### START QUESTION 2 CODE ###

## START QUESTION 2 Part D CODE ##

# Fitting a lmer model with a random intercept using the REML method
measles_ri_reml <- lmer(Avg_Titer_Log ~ Age_At_Draw + (1|ID), 
                        data = measles_data, REML = TRUE)

summary(measles_ri_reml)


```
```{r}

# Fitting a lmer model with a random intercept using the ML method
measles_ri_ml <- lmer(Avg_Titer_Log ~ Age_At_Draw + (1|ID), 
                        data = measles_data, REML = FALSE)

summary(measles_ri_ml)

## FINISH QUESTION 2 PART D CODE ##

```

#### Part E
What are the fixed effects estimates with 95\%CI and p-values for both fits? How do they compare? Explain.

```{r, echo = F}

## START QUESTION 2 PART E CODE ##

reml_ri_results <- broom.mixed::tidy(measles_ri_reml,
                                     conf.int = TRUE)[c(1:2),] %>%
  select(term,estimate,conf.low,conf.high,p.value) %>%
  mutate(p.value = format.pval(p.value),
         term = c("Intercept","Age At Draw"))

ml_ri_results <- broom.mixed::tidy(measles_ri_ml,
                                   conf.int = TRUE)[c(1:2),] %>%
  select(term,estimate,conf.low,conf.high,p.value) %>%
  mutate(p.value = format.pval(p.value),
         term = c("Intercept","Age At Draw"))

ri_comp_df <- rbind(reml_ri_results,ml_ri_results)

ri_comp_table <- kbl(ri_comp_df,
                     col.names = c("Term","Estimate","95% Conf.Low",
                                   "95% Conf.High","P-Value"),
                     digits = 5, booktabs = TRUE, align = "cc") %>%
  kable_styling(latex_options = "HOLD_position") %>%
  pack_rows("REML",1,2) %>%
  pack_rows("ML",3,4)

ri_comp_table

## FINISH QUESTION 2 PART E CODE ##

```
\
The REML method has a slightly higher intercept coefficient and a slightly lower "Age At Draw" coefficient compared to the ML method. The REML method also has a slightly wider 95\% CI for the intercept term and a slightly narrower 95\% CI for the "Age At Draw" term compared to the ML method. The p-value for the intercept term is effectively the same and significant between both methods. The p-value for the "Age At Draw" term is slightly lower for the ML method, but neither REML or ML have a significant "Age At Draw" coefficient. Because the ML method tends to have a downward bias for variance the intercept for the ML method has narrower 95\% confidence intervals compared to the REML method for the model fitting a random slope. 

#### Part F
Interpret these findings in 1-2 sentences. 

Both models have approximately the same output. The intercept of 9.10 is the expected log of the average titer at age 0, which is significant in both models with p-values <0.001. The "Age At Draw" coefficient is the expected change in titer as age progresses each year, with the coefficient meaning there is an expected increase of 0.005 in log of titer each year. This coefficient is insignificant with a p-value >0.05. 

#### Part G
What test was used to generate the p-value and what were the denominator DF? 

For both the REML and ML methods the Satterthwaite's method was used to generate the p-value. For the REML method the degrees of freedom for the intercept was 76.57 (closer to the number of subjects), and for the "Age At Draw" term it was 425.3 (Closer to the number of total observations). For the ML method the degrees of freedom for the intercept was 79.49 (closer to the number of subjects), and for the "Age at Draw" term it was 426.6 (closer to the number of observations). 

#### Part H
Use the anova package to test the significance of the slope on age using a Satterwaithe and a Kenward-Roger DF adjustment. Present and compare the denominator DF. Provide a 1-2 sentence intuitive answer as to why they differ (or are similar). Were there any differences in your study conclusion using different tests? 

```{r, echo = F}

## START QUESTION 2 PART H CODE ##

satterthwaite_ri_reml <- anova(measles_ri_reml, ddf = "Satterthwaite")

kenward_roger_ri_reml <- anova(measles_ri_reml, ddf = "Kenward-Roger")

ri_ddf_comp <- data.frame(ddf_method = c("Satterthwaite",
                                         "Kenward-Roger"),
                          ddf = c(satterthwaite_ri_reml$DenDF,
                                  kenward_roger_ri_reml$DenDF),
                          p_value = c(satterthwaite_ri_reml$`Pr(>F)`,
                                      kenward_roger_ri_reml$`Pr(>Chisq)`))

ri_ddf_table <- kbl(ri_ddf_comp,
                    caption = "DDF for Different Methods",
                    col.names = c("Method","DDF","P-Value"),
                    booktabs = TRUE, align = "cc", digits = 3) %>%
  kable_styling(latex_options = "HOLD_position")

ri_ddf_table

## FINISH QUESTION 2 PART H CODE ##

```
\
The DDF are nearly identical for the slope between the Satterthwaite and Kenward-Roger methods. The sample size may be sufficient to overcome the unbalanced data (where the Satterthwaite tends to performs worse). The p-values were the same to the third decimal place, meaning the same conclusion, that the slope is not significant in the random intercept model.  

#### Part I
What were the estimates of $G_i$, $R_i$, and $V_i$ for this model using both approaches? Interpret the different sources of variation. What estimates will be more biased (ML and REML)? Why? 

**REML**

$G_i$ and $R_i$ are both from the model summary. $V_i$ is the summation of these two components:

* $G_i$ = 2.0834
* $R_i$ = $\sigma_e$ = 0.1154; This estimate will be in a matrix with the format $\sigma_e I_n$
* $V_i$ = 2.1988; This estimate will be in a matrix with dimensions (nx1). 

**ML**

$G_i$ and $R_i$ are both from the model summary. $V_i$ is the summation of these two components:

* $G_i$ = 2.0299
* $R_i$ = $\sigma_e$ = 0.1151; This estimate will be in a matrix with the format $\sigma_e I_n$
* $V_i$ = 2.1450; This estimate will be in a matrix with dimensions (nx1). 

The estimates from the ML method will be more biased (downward). 

#### Part J
Compute the ICC and interpret. What source of variation is largest, within or between subject variation? $G_i$ is the between subject variation, $R_I$ is the within subject variation, and $V_i$ is the total variation for a specific subject. 

**REML**

$$ICC = \frac{\sigma_{b0}}{\sigma_{b0}+\sigma_e}=\frac{2.0834}{2.0834+0.1154}=0.948$$
In the REML method there is more between subject variation compared to within subject variation. 

**ML**

$$ICC = \frac{\sigma_{b0}}{\sigma_{b0}+\sigma_e}=\frac{2.0299}{2.0299+0.1151}=0.946$$
In the ML method there is more between subject variation compared to within subject variation. 

#### Part K
Using the ML estimates, create the EBLUP and the fitted estimates. The individual fitted values of the outcome are a weighted combination of two quantities. What are these two quantities? What determines the weight of the individual estimate towards each of the quantities? 

```{r, echo = F}

## START QUESTION 2 PART K CODE ##

# Calculating the EBLUPs.
ri_eblup <- ranef(measles_ri_ml)

# Calculating the fitted estimates. 
ri_fitted <- fitted(measles_ri_ml)

## FINISH QUESTION 2 PAT K CODE ## 

```
The individual fitted values are a combination of subject specific data (random effects) and group averaged data. The weight of individual estimates is the difference between the population average profile and the observed data. 

#### Part L
Make a plot of the estimated individual specific curves compared to the observed data. How well do you think this model is capturing the the variation in the data and the age trends in the data? Provide an interpretation in a few sentences. 

```{r, echo = F}

## START QUESTION 2 PART L CODE ##

# Combining the fitted data with the original data. 
measles_ri_fitted <- cbind(measles_data,ri_fitted)

# Making a plot of the estimated fitted curves compared to the observed data. 
measles_ri_fit_plot <- ggplot(data = measles_ri_fitted, aes(x = Age_At_Draw,
                                                            y = ri_fitted,
                                                            group = ID)) +
  geom_line(aes(color = "Fitted")) +
  geom_line(aes(x = Age_At_Draw,
                y = Avg_Titer_Log,
                group = ID, color = "Observed")) +
  labs(title = "Comparison Between Subject Specific Curves and Observed Data",
       y = "Log(Average Titer", x = "Age at Draw",
       caption = "Random Intercept Model") +
  scale_colour_manual(name = "Lines",
                      breaks = c("Fitted","Observed"),
                      values = c("Fitted" = "red","Observed" = "black")) +
  theme_bw()

measles_ri_fit_plot

## FINISH QUESTION 2 PART L CODE ##

```


# Question 3

#### Part A
Write out the random intercept model for these data in subject level notation including indices for matrices. 

$$Y_i = X_i\beta + Z_ib_i + E_i$$
Where each matrix has the following dimensions:

* $Y_i: (n_i \times 1)$; $n_i$ refers to the number of time points (age). Outcome is the log of average titer. 
* $X_i: (n_i \times p)$; $n_i$ refers to the number of time points(age) and p is the number of covariates plus the intercept. The only covariates are the number of time points (age).
* $\beta: (p \times 1)$; $p$ refers to the number of covariates (measurements at a certain age plus the intercept). 
* $Z_i: (n_i \times q)$; $n_i$ refers to the number of time points (age). $q$ refers to the number of covariates for the random effects. In this case there is a random intercept and a random slope, so $q=2$. 
* $b_i: (q \times 1)$; $q$ refers to the number of covariates for the random effects. In this case there is a random intercept and random slope, so $q=2$. 
* $E_i: (n_i \times 1)$; $n_i$ refers to the number of time points (age). Each individual outcome has its own error term. 

#### Part B
What is the format for $G_i$ and $R_i$ that will be assumed in the lmer R function when you fit the random intercept model? Please write the format for these two matrices and interpret. Note we want the random effects to have an unstructured $G_i$ matrix.

The variability of the random effect will be a matrix with $(q_i \times q_i)$ dimensions. Because there is a random intercept and a random slope the $G_i$ matrix will have dimensions of $(2 \times 2)$.  
$$
G_i = 
\begin{bmatrix}
  \tau_0^2 & \tau_{01} \\
  \tau_{10} & \tau_1^2
\end{bmatrix}
=
\begin{bmatrix}
  \sigma_0^2 & \sigma_{01}^2 \\
  \sigma_{10} & \sigma_1^2
\end{bmatrix}
$$
It is usually not possible to estimate both $G$ and an unstructured $R_i$, meaning that $R_i=\sigma_e^2I_n$ (an independence matrix). The dimensions of $R_i$ are $(n_i \times n_i)$, which in this case means a square matrix where $n_i$ is the number of time points (measurements at different ages) for each subject. Because different subjects have different time points the dimensions of the $R_i$ matrix will change between subjects.  

#### Part C
Fit a random intercept and slope model for these data using the lmer R function with REML and ML estimation approaches. Provide code and output. 

```{r}

### START QUESTION 3 CODE ###

## START PART C CODE ##

# Fitting a lmer model with a random intercept and slope  using the REML method.
measles_ri_rs_reml <- lmer(Avg_Titer_Log ~ Age_At_Draw + (1 + Age_At_Draw|ID), 
                        data = measles_raw, REML = TRUE)

summary(measles_ri_rs_reml)

```
```{r}

# Fitting a lmer model with a random intercept and slope using the ML method
measles_ri_rs_ml <- lmer(Avg_Titer_Log ~ Age_At_Draw + (1 + Age_At_Draw|ID), 
                        data = measles_raw, REML = FALSE)

summary(measles_ri_rs_ml)

## FINISH QUESTION 3 PART C CODE ##

```

#### Part D
What are the fixed effects estimates with 95\%CI and p-values for both fits? How do they compare? Explain.

```{r, echo = F}

## START QUESTION 3 PART D CODE ##

reml_ri_rs_results <- broom.mixed::tidy(measles_ri_rs_reml,
                                     conf.int = TRUE)[c(1:2),] %>%
  select(term,estimate,conf.low,conf.high,p.value) %>%
  mutate(p.value = format.pval(p.value),
         term = c("Intercept","Age At Draw"))

ml_ri_rs_results <- broom.mixed::tidy(measles_ri_rs_ml,
                                   conf.int = TRUE)[c(1:2),] %>%
  select(term,estimate,conf.low,conf.high,p.value) %>%
  mutate(p.value = format.pval(p.value),
         term = c("Intercept","Age At Draw"))

ri_rs_comp_df <- rbind(reml_ri_rs_results,ml_ri_rs_results)

ri_rs_comp_table <- kbl(ri_rs_comp_df,
                     col.names = c("Term","Estimate","95% Conf.Low",
                                   "95% Conf.High","P-Value"),
                     digits = 5, booktabs = TRUE, align = "cc") %>%
  kable_styling(latex_options = "HOLD_position") %>%
  pack_rows("REML",1,2) %>%
  pack_rows("ML",3,4)

ri_rs_comp_table

## FINISH QUESTION 3 PART D CODE ##

```

The REML method had a slightly lower intercept and a slightly higher "Age At Draw" coefficient. Intercepts were significant in both models and "Age At Draw" coefficients were insignificant in both models. Additionally the ML model gave a warning concerning convergence. Because the variance estimate of the ML method tends to be biased downwards this is why the 95\% confidence intervals of the ML method are slightly narrower here after fitting both a random slope and a random intercept. 

#### Part E
Interpret these finding in 1-2 sentences.

Both models have approximately the same outcomes. The intercept means that subjects at age 0 are expected to have a log of average titer of 8.36, which is significant with a p-value <0.001. The "Age at Draw" coefficient means that for every year subjects are expected to increase their log of average titer by 0.026. This estimate is insignificant in both models, with p-values > 0.05. 

#### Part F
What test was used to generate the p-value and what were the denominator DF? 

For both the REML and ML methods the Satterthwaite's method was used to generate the p-value. For the REML method the degrees of freedom for the intercept was 37.92 (closer to the number of subjects), and for the "Age At Draw" coefficient it was 34.59 (closer to the number of subjects). For the ML method the degrees of freedom for the intercept was 38.51 (closer to the number of subjects), and for the "Age At Draw" coefficient it was 35.09 (closer to the number of subjects). 

#### Part G
How did the denominator DF in the test statistic differ between the random intercept and random slope model? Explain what is happening here (if anything). 

For the test statistics denominator DF in the random intercept only model was closer to the number of subjects. Once a random slope was added to the model the test statistic denominator DF was closer to the number of subjects. This makes sense as fitting a random slope for each subjects uses up DF, and inferences on slope are collapsed closer to the number of subjects compared to the number of observations after random slopes are fitted. 

#### Part H
Use the anova package to test the significance of the slope on age using a Satterthwaite and a Kenward-Roger DF adjustment for the REML model. Present and compare the denominator DF. Provide a 1-2 sentence intuitive answer as to why they differ (or are similar). Were there any differences in your conclusions between these different testing approaches. 

```{r, echo = F}

satterthwaite_ri_rs_reml <- anova(measles_ri_rs_reml,ddf = "Satterthwaite")

kenward_roger_ri_rs_reml <- anova(measles_ri_rs_reml,ddf = "Kenward-Roger")

ri_rs_reml_df <- data.frame(Method = c("Satterthwaite","Kenward-Roger"),
                            DDF = c(satterthwaite_ri_rs_reml$DenDF,
                                   kenward_roger_ri_rs_reml$DenDF),
                            p_value <- c(satterthwaite_ri_rs_reml$`Pr(>F)`,
                                         kenward_roger_ri_rs_reml$`Pr(>F)`))

ri_rs_reml_df_tbl <- kbl(ri_rs_reml_df,
                         caption = "Random Intercept-Slope REML DF",
                         col.names = c("Method","DDF","P-Value"),
                         booktabs = TRUE, align = "cc", digits = 3) %>%
  kable_styling(latex_options = "HOLD_position")

ri_rs_reml_df_tbl

```
The DDF for the Satterthwaite method is less than the Kenward-Roger method. Because a random slope was fitted this grouped data for the slope from being individual observations as it was in the random intercept only model to being observations within subjects as age progressed. This reduction accounts for both the DDF being closer to the number of subjects instead of the number of observations, as well as the difference in DDF observed between the two methods. Due to unbalanced data between subjects the Kenward-Roger method should be chosen. The p-values are very close however, and neither is statistically significant. 

#### Part I
Were there any differences between tests and denominator DF between the random intercept and random slope models? Explain.

Between the random intercept and random intercept/slope models neither p-values are significant. However, the p-values from the random intercept/slope models are much closer to the level of significance due to accounting for between subject variation in slopes. Between the random intercept and random intercept/slope models the degrees of freedom in the random intercept model is much higher and much closer to the number of observations. After accounting for between subject differences in slopes with the random slope/intercept model the DF are closer to the number of subjects. 

#### Part J
What were the estimates of $G_i$, $R_i$, and $V_i$ for this model using both approaches? Interpret the different sources of variation. What estimates will be more biased (ML and REML)? Why? 

All values were extracted from the model outputs. 

**REML**

* $G_i$: 

$$
G_i =
\begin{bmatrix}
  \sigma_{b0}^2 & \sigma_{b,01} \\
  \sigma_{b,01} & \sigma_{b1}^2
\end{bmatrix}
=
\begin{bmatrix}
  11.15 & -0.91 \\
  -0.91 & 0.0061 
\end{bmatrix}
$$

* $R_i$: $\sigma_e$ = 0.0606; $R_i$ is a matrix with form $\sigma_e I_n$
* $V_i$:

$$
V_i = 
\begin{bmatrix}
  1 & age_{i1} \\
  1 & age_{i2} \\
  \vdots & \vdots \\
  1 & age_{in}
\end{bmatrix}
\begin{bmatrix}
  11.15 & -0.91 \\
  -0.91 & 0.0061 
\end{bmatrix}
\begin{bmatrix}
  1 & 1 & \cdots & 1 \\
  age_{i1} & age_{i2} & \cdots & age_{in}
\end{bmatrix}
+
0.0606 I_n
$$

**ML**

* $G_i$

$$
G_i =
\begin{bmatrix}
  \sigma_{b0}^2 & \sigma_{b,01} \\
  \sigma_{b,01} & \sigma_{b1}^2
\end{bmatrix}
=
\begin{bmatrix}
  10.89 & -0.91 \\
  -0.91 & 0.0059 
\end{bmatrix}
$$
* $R_i$: $\sigma_e$ = 0.0605; $R_i$ is a matrix with form $\sigma_e I_n$
* $V_i$: 

$$
V_i = 
\begin{bmatrix}
  1 & age_{i1} \\
  1 & age_{i2} \\
  \vdots & \vdots \\
  1 & age_{in}
\end{bmatrix}
\begin{bmatrix}
  10.89 & -0.91 \\
  -0.91 & 0.0059 
\end{bmatrix}
\begin{bmatrix}
  1 & 1 & \cdots & 1 \\
  age_{i1} & age_{i2} & \cdots & age_{in}
\end{bmatrix}
+
0.0605 I_n
$$

#### Part K
Using the ML estimates, compute the ICC for the slope and interpret. What percentage of variation is due to the random effect on slope. 

$$ICC(Slope) = \frac{\sigma_{b1}^2}{\sigma_{b0}^2+\sigma_{b1}^2+\sigma_e^2}=\frac{0.005917}{10.891284+0.005917+0.060546}=5.3998 \times 10^{-4}$$
The ICC for slope is very small meaning that almost none of the variance is due to the random effect on slope. This means that there is not a lot of variance in the slopes between subjects. 

$$ICC(Intercept) = \frac{\sigma_{b0}^2}{\sigma_{b0}^2+\sigma_{b1}^2+\sigma_e^2}=\frac{10.891284}{10.891284+0.005917+0.060546}=0.994$$
The ICC for the intercept accounts for nearly of the variance in the model. This means that there is a lot of variance in the intercepts between subjects. In other words, subjects start at vastly different average titer levels. 

#### Part L
Using the ML estimates, create the EBLUP and the fitted estimates. There is nothing to turn in for this question but the code. 

```{r}

## START QUESTION 3 PART L CODE ##

# Calculating the estimates. Converting to data.frame to extract the 
ri_rs_eblups <- ranef(measles_ri_rs_ml,condVar = TRUE)

# Calculating the fitted values. 
ri_rs_fitted <- fitted(measles_ri_rs_ml)

## FINISH QUESTION 3 PART L CODE ##

```

#### Part M
Make a plot of the estimated individual specific curves compared to the observed data. How well do you think this model is capturing the variation in the data and the age trends in the data? Provide an interpretation in a few sentences. 

```{r, echo = F}

## START QUESTION 3 PART M CODE ##

# Combining the fitted data with the original data. 
measles_ri_rs_fitted <- cbind(measles_data,ri_rs_fitted)

# Making a plot of the estimated fitted curves compared to the observed data. 
measles_ri_rs_fit_plot <- ggplot(data = measles_ri_rs_fitted, 
                                 aes(x = Age_At_Draw,
                                     y = ri_rs_fitted,
                                     group = ID)) +
  geom_line(aes(color = "Fitted")) +
  geom_line(aes(x = Age_At_Draw,
                y = Avg_Titer_Log,
                group = ID, color = "Observed")) +
  labs(title = "Comparison Between Subject Specific Curves and Observed Data",
       y = "Log(Average Titer", x = "Age at Draw",
       caption = "Random Intercept and Random Slope Model") +
  scale_colour_manual(name = "Lines",
                      breaks = c("Fitted","Observed"),
                      values = c("Fitted" = "red","Observed" = "black")) +
  theme_bw()

measles_ri_rs_fit_plot

## FINISH QUESTION 3 PART M CODE ##

### FINISH QUESTION 3 CODE ###

```
For each individual subject the random intercept/slope model more closely models the trend between age and the log of average titer. Most subjects have a roughly linear trend with time and the random slopes model these well, although a few subjects have trends which are not linear. 

#### Part N
Base on the fits do you think the random slope is a critical additional component to add to the model? Explain.

In this scenario the random slopes do better at modeling the trends over time. In the intercept only model the average slope is increasing for all subjects. In the random slope/intercept model the subjects are allowed to have declining slopes, better modeling the actual data. 

#### Part O
The investigator is leery of these mixed effects models. How would you show him/her what the random intercept and random slope model did for estimation compared to just fitting a bunch of regression models, one for each person? 

Using a random intercept/slope model allows for each subject to be modeled separately, which in effect provides the same inferences on subjects that fitting multiple regression models for each subject would. The random intercept/slope model also provides the average trends, which are what will be used for making inferences on people who have had measles vaccines. 

\newpage

# Part 2


## Question 3

```{r, echo = F}

# Loading in data.
cereal_raw <- read.csv("C:/Users/domin/Documents/Biostatistics Masters Program/Fall 2023/BIOS 6643 - ADL/BIOS6643_ALD/Homework 5/Cereal2.csv")

# Formatting data. 
cereal_data <- cereal_raw %>% 
  select(Cond,C1,FamMem,Sex,Age1,Ht1,Wt1) %>%
  subset(FamMem == 3)

```

#### Part A
Use a Poisson GLM (i.e. Poisson regression) to estimate the association between condition (group) and number of breakfast servings, adjusting for sex and weight.

```{r, echo = F}

poisson_mod <- glm(Cond ~ C1 + Sex + Age1, 
                   family = poisson, data = cereal_data)

broom.mixed::tidy(poisson_mod, exp = T, conf.int = T) %>%
  mutate(p.value = format.pval(p.value)) %>%
  select(term,estimate,std.error,conf.low,conf.high,p.value) %>%
  kbl(digits = 4, booktabs = T, align = "cc",
      caption = "Condition - Poisson Model",
      col.names = c("Term","Estimate","Std.Error",
                    "95% Conf.Low","95% Conf.High","P-Value")) %>%
  kable_styling(latex_options = "HOLD_position")

```

#### Part B
Repeat (a) allowing for overdispersion by using quasilikelihood with the Poisson GLM. 

```{r, echo = F}

quasipoisson_mod <- glm(Cond ~ C1 + Sex + Age1, 
                   family = quasipoisson, data = cereal_data)

broom.mixed::tidy(quasipoisson_mod, exp = T, conf.int = T) %>%
  mutate(p.value = format.pval(p.value)) %>%
  select(term,estimate,std.error,conf.low,conf.high,p.value) %>%
  kbl(digits = 4, booktabs = T, align = "cc",
      caption = "Condition - Poisson Model",
      col.names = c("Term","Estimate","Std.Error",
                    "95% Conf.Low","95% Conf.High","P-Value")) %>%
  kable_styling(latex_options = "HOLD_position")

```

